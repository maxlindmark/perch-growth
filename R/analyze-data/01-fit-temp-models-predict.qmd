---
title: "Fit temperature models and predict growing season temperature"
author: "Max Lindmark, Jan Ohlberger, Anna Gårdmark"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format: 
  html:
    code-fold: true
    embed-resources: true
    fig-width: 12
    fig-height: 10
editor: source
execute: 
  echo: true
  eval: true
  cache: true
---

```{r setup}
#| include: false
#| cache: false
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 12,
  fig.asp = 0.618,
  fig.align ='center'
)
```

## Load libraries

```{r libraries and functions}
#| cache: false
pkgs <- c("here","tidyverse", "tidylog", "RColorBrewer", "viridis", "sdmTMB", "sdmTMBextra", "patchwork", "RCurl", "tidylog") 

# minpack.lm needed if using nlsLM()
if(length(setdiff(pkgs,rownames(installed.packages()))) > 0){

    install.packages(setdiff(pkgs, rownames(installed.packages())), dependencies = T)
  
  }

invisible(lapply(pkgs, library,character.only = T))

# devtools::install_github("seananderson/ggsidekick") # not on CRAN 
library(ggsidekick)
theme_set(theme_sleek())

# Set path:
home <- here::here()
```

Load cache

```{r}
# qwraps2::lazyload_cache_dir(path = paste0(home, "/R/analyze-data/01-fit-temp-models-predict_cache/html"))
```

## Read data

```{r}
d <- read_csv(paste0(home, "/output/temp_data_for_fitting.csv"))

d <- d |> mutate(area = as.factor(area),
                 source_f = as.factor(source),
                 year_f = as.factor(year))

# Drop VN, no logger data?
d |> group_by(area) |> summarise(n_source = length(unique(source_f))) 

# Drop data in SI_HA and BT before onset of warming?
d2 <- d |>
  mutate(discard = "N",
         discard = ifelse(area == "BT" & year <= 1980, "Y", discard),
         discard = ifelse(area == "SI_HA" & year <= 1972, "Y", discard)) |> 
  filter(discard == "N")
```

## Fit models
Source as independent or interactive effect

```{r}
#| eval: false
#| cache: false
# library(brms)
# # Too slow...
# testm <- brm(temp ~ area*year_f + source_f + s(yday, by = area, bs = "cc"), 
#              data = d |> sample_n(5000),
#              family = student(),
#              chains = 2,
#              cores = 2,
#              knots = list(yday = c(0.5, 364.5))
#              )
# 
# summary(testm)
# 
# detach("package:brms", unload = TRUE)
# 
# library(QRM)
# 
# fit.st(data = d |> sample_n(500))
```

```{r}
m <- sdmTMB(temp ~ area*year_f + source_f + s(yday, by = area, bs = "cc"), 
            data = d,
            family = student(df = 5),
            spatial = "off",
            spatiotemporal = "off",
            knots = list(yday = c(0.5, 364.5)),
            control = sdmTMBcontrol(newton_loops = 1))
```

Try alternative degrees of freedom

```{r}
#df=20 (effectively gaussian)
m2 <- sdmTMB(temp ~ area*year_f + source_f + s(yday, by = area, bs = "cc"), 
            data = d,
            family = student(df = 20),
            spatial = "off",
            spatiotemporal = "off",
            knots = list(yday = c(0.5, 364.5)),
            control = sdmTMBcontrol(newton_loops = 1))

# df = 9
m3 <- sdmTMB(temp ~ area*year_f + source_f + s(yday, by = area, bs = "cc"), 
            data = d,
            family = student(df = 9),
            spatial = "off",
            spatiotemporal = "off",
            knots = list(yday = c(0.5, 364.5)),
            control = sdmTMBcontrol(newton_loops = 1))

# df=4
m4 <- sdmTMB(temp ~ area*year_f + source_f + s(yday, by = area, bs = "cc"), 
            data = d,
            family = student(df = 4),
            spatial = "off",
            spatiotemporal = "off",
            knots = list(yday = c(0.5, 364.5)),
            control = sdmTMBcontrol(newton_loops = 1))

# Plot all residuals
mcmc_res <- residuals(m, type = "mle-mcmc",
                      mcmc_samples = sdmTMBextra::predict_mle_mcmc(m,
                                                                   mcmc_iter = 201,
                                                                   mcmc_warmup = 200))

mcmc_res20 <- residuals(m2, type = "mle-mcmc",
                        mcmc_samples = sdmTMBextra::predict_mle_mcmc(m2,
                                                                     mcmc_iter = 201,
                                                                     mcmc_warmup = 200))

mcmc_res9 <- residuals(m3, type = "mle-mcmc",
                       mcmc_samples = sdmTMBextra::predict_mle_mcmc(m3,
                                                                    mcmc_iter = 201,
                                                                    mcmc_warmup = 200))

mcmc_res4 <- residuals(m4, type = "mle-mcmc",
                       mcmc_samples = sdmTMBextra::predict_mle_mcmc(m4,
                                                                    mcmc_iter = 201,
                                                                    mcmc_warmup = 200))

dres <- d |> mutate("df=5" = mcmc_res,
                    "df=20" = mcmc_res20,
                    "df=9" = mcmc_res9,
                    "df=4" = mcmc_res4) |> 
  select(`df=5`, `df=20`, `df=9`, `df=4`) |> 
  pivot_longer(everything())

ggplot(dres, aes(sample = value)) +
  stat_qq(size = 0.75, shape = 21, fill = NA) +
  facet_wrap(~factor(name, levels = c("df=20", "df=9", "df=5", "df=4"))) +
  stat_qq_line() +
  labs(y = "Sample Quantiles", x = "Theoretical Quantiles") + 
  theme(aspect.ratio = 1)
```

```{r}
#| include: false
#| eval: false
#| cache: false
# Doesn't fit! I think it's because some area*year combination have the same errs and no other source; maybe not identifiable?
# m2 <- sdmTMB(temp ~ area*year_f + area*source_f + s(yday, by = area, bs = "cc"),
#              data = d |> filter(!area %in% c("BT", "SI_HA")),
#              family = student(df = 6),
#              spatial = "off",
#              spatiotemporal = "off",
#              knots = list(yday = c(0.5, 364.5)),
#              control = sdmTMBcontrol(newton_loops = 1))
```

```{r}
#AIC(m, m2)
```

## Check fit

```{r}
sanity(m)

ggplot(d, aes(sample = mcmc_res)) +
  stat_qq() +
  stat_qq_line() +
  labs(y = "Sample Quantiles", x = "Theoretical Quantiles") + 
  theme(aspect.ratio = 1)

ggsave(paste0(home, "/figures/supp/qq_temp.pdf"), width = 11, height = 11, units = "cm")
```

## Predict

```{r}
# Make a new data frame and predict!
nd <- data.frame(expand.grid(yday = seq(min(d$yday), max(d$yday), by = 1),
                             area = unique(d$area),
                             year = unique(d$year))) |>
  mutate(source = "logger") |> 
  mutate(id = paste(year, area, sep = "_"),
         source_f = as.factor(source),
         year_f = as.factor(year)) 

# Predict
nd$pred <- predict(m, newdata = nd)$est
```

In order to have a lower temperature in before-nuclear times (without any data to inform that), we can use the nearby areas.. so FM informs BT prior to nuclear

```{r}
nd <- nd |> 
  mutate(keep = "Y",
         keep = ifelse(area == "BT" & year < 1980, "N", keep),
         keep = ifelse(area == "SI_HA" & year < 1972, "N", keep)) |>
  filter(keep == "Y")
  
nd_sub <- nd |> 
  mutate(keep = "N",
         keep = ifelse(area == "FM" & year < 1980, "Y", keep), # use FM instead of BT
         keep = ifelse(area == "SI_EK" & year < 1972, "Y", keep)) |> # use SI_EK instead of SI_HA
  filter(keep == "Y")

# Now change the labels to BT and SI_EK...
nd_sub <- nd_sub |> 
  mutate(area = ifelse(area == "FM", "BT", "SI_HA"))

# Bind rows and plot only the temperature series we will use for growth modelling
nd <- bind_rows(nd, nd_sub) |> select(-keep)
```

Keep track of the years for which we have cohorts for matching with cohort data

```{r}
gdat <- readr::read_csv("https://raw.githubusercontent.com/maxlindmark/perch-growth/master/data/for-analysis/dat.csv")

gdat$area_cohort_age <- as.factor(paste(gdat$area, gdat$cohort, gdat$age_bc))

gdat <- gdat |>
  group_by(area_cohort_age) |> 
  filter(n() > 10)

gdat <- gdat |> 
  filter(age_catch > 3) |> 
  group_by(area) |>
  summarise(min = min(cohort)) |> 
  arrange(min)

nd <- left_join(nd, gdat, by = "area") |>
  mutate(growth_dat = ifelse(year >= min, "Y", "N"))
```

## Plot predictions

```{r}
nd |> 
  filter(growth_dat == "Y") |> 
  ggplot(aes(yday, y = year, fill = pred, color = pred)) +
    geom_raster() +
    facet_wrap(~area, ncol = 3) +
    scale_fill_viridis(option = "magma") +
    scale_color_viridis(option = "magma") +
    labs(x = "Yearday", y = "Year", color = "Predicted SST (°C)", fill = "Predicted SST (°C)")
```

Growing season? This might be different for different areas... 

```{r}
# Find day of the year where temperature exceeds 10C by area across years
gs_area <- nd |> 
  group_by(area, yday) |> 
  summarise(mean_pred = mean(pred)) |>
  ungroup() |> 
  filter(mean_pred > 10) |> 
  group_by(area) |> 
  summarise(gs_min = min(yday),
            gs_max = max(yday))

nd <- left_join(nd, gs_area, by = "area")

gs_area$mean_pred <- 10

# Plot!
nd |> 
  filter(growth_dat == "Y") |> 
  group_by(area, yday) |> 
  summarise(mean_pred = mean(pred)) |> 
  ggplot(aes(yday, mean_pred)) +
  geom_line() +
  labs(x = "Yearday", y = "Year", color = "Predicted SST (°C)", fill = "Predicted SST (°C)") + 
  facet_wrap(~area) +
  geom_point(data = gs_area, aes(gs_min, mean_pred), inherit.aes = FALSE, color = "tomato2") + 
  geom_point(data = gs_area, aes(gs_max, mean_pred), inherit.aes = FALSE, color = "tomato2") +
  geom_hline(yintercept = 10, linetype = 2)
```

Detailed exploration of predictions

```{r}
# Loop trough all areas, plot temperature as a function of yday, color by data source, facet by year

for(i in unique(nd$area)) {
  
  plotdat <- nd |> filter(area == i)
  
  print(
    ggplot(plotdat, aes(yday, pred, linetype = "Model prediction (logger)")) + 
      scale_color_brewer(palette = "Accent") + 
      facet_wrap(~year) + 
      geom_point(data = filter(d, area == i & year > min(plotdat$year)), aes(yday, temp, color = source),
                 size = 0.75) + 
      geom_line() + 
      labs(title = paste("Area = ", i), color = "", linetype = "") + 
      guides(color = guide_legend(title.position="top", title.hjust = 0.5)) + 
      theme_sleek(base_size = 8) +
      theme(legend.position = c(0.7, 0.03), 
            legend.direction = "horizontal",
            legend.spacing.y = unit(-0.3, "cm")) + 
      labs(x = "Day of the year", y = "Predicted SST (°C)")
  )
  
  ggsave(paste0(home, "/figures/supp/temp_pred_yday_area_", i, ".pdf" ), width = 17, height = 17, units = "cm")
  
}
```  

Plot summarized data and predictions

```{r}
dsum <- d |> 
  group_by(year, area, source) |> 
  summarise(temp = mean(temp)) |> 
  mutate(type = "data")

preds <- nd |> 
  filter(growth_dat == "Y" & source == "logger") |> 
  group_by(area, year) |> 
  summarise(temp = mean(pred)) |> 
  mutate(type = "model")

# Now do by growing season instead
preds_gs <- nd |> 
  filter(growth_dat == "Y" & source == "logger") |> 
  filter(yday >= gs_min & yday <= gs_max) |> 
  group_by(area, year) |> 
  summarise(temp_gs = mean(pred))

preds <- left_join(preds, preds_gs, by = c("area", "year"))

ggplot(preds, aes(temp, temp_gs, color = area)) + 
  geom_point()

ggplot(preds, aes(year, temp)) + 
  geom_point(data = dsum, aes(year, temp, color = source), size = 0.75, alpha = 0.75) + 
  scale_color_brewer(palette = "Accent") +
  geom_line(linewidth = 0.5, color = "grey20") + 
  facet_wrap(~area)
```

Now see if there is a systematic pattern in the difference between predicted and observed logger data, which could indicate that the source effect isn't global but area-specific.

```{r}
dlog <- d |> 
  filter(source == "logger") |> 
  mutate(type = "data",
         id = paste(area, year, yday, sep = "_")) |> 
  select(id, temp) |> 
  group_by(id) |> 
  summarise(obs = mean(temp)) # sometimes we have more than 1 observation per id

# dlog |> 
#   group_by(id) |> 
#   summarise(n = n()) |> 
#   distinct(n)

preds_log <- nd |> 
  filter(growth_dat == "Y" & source == "logger") |> 
  mutate(type = "model",
         id = paste(area, year, yday, sep = "_")) |> 
  filter(id %in% unique(dlog$id)) |> 
  ungroup() |> 
  left_join(dlog, by = "id")

preds_log |> 
  mutate(resid = pred - obs) |> 
  ggplot(aes(as.factor(area), resid, group = as.factor(area))) +
  #geom_jitter(alpha = 0.05, color = "grey20", height = 0, width = 0.2) + 
  geom_violin(fill = "grey70", color = NA) +
  geom_boxplot(width = 0.2, outlier.colour = NA, outlier.color = NA, outlier.fill = NA) +
  guides(color = "none") +
  geom_hline(yintercept = 0, linetype = 2, color = "tomato3", linewidth = 0.75) + 
  labs(x = "Area", y = "Manual residuals")
```

Make final plot

```{r}
order <- preds |>
  group_by(area) |> 
  summarise(mean_temp = mean(temp)) |> 
  arrange(desc(mean_temp))

order
# Save plot order..

topt <- 10.6 # Overall t_opt from 02-fit-vbge.qmd! Update if needed

# Add latitude
area <- c("BS", "BT", "FB", "FM", "HO", "JM", "MU", "RA", "SI_EK", "SI_HA", "TH", "VN")
nareas <- length(area)
lat <- c(60, 60.4, 60.3, 60.5, 63.7, 58, 59, 65.9, 57.3, 57.4, 56.1, 57.5)
lon <- c(21.5, 18.1, 19.5, 18, 20.9, 16.8, 18.1, 22.3, 16.6, 16.7, 15.9, 16.9)
area_attr <- data.frame(cbind(area = area, lat = lat, lon = lon)) |>
  mutate_at(c("lat","lon"), as.numeric) |> 
  arrange(desc(lat))

ggplot(preds, aes(year, temp, color = temp)) + 
  facet_wrap(~factor(area, levels = area_attr$area), ncol = 3) + 
  geom_hline(yintercept = topt, linewidth = 0.3, linetype = 2, color = "grey") +
  geom_line() +
  labs(x = "Year", y = "Model-predicted annual average temperature") + 
  scale_color_viridis(option = "magma", name = "Area") +
  guides(color = "none") 

preds |> 
  group_by(area) |> 
  summarise(min = min(year),
            max = max(year)) |> 
  arrange(min)

ggsave(paste0(home, "/figures/annual_average_temperature.pdf"), width = 17, height = 17, units = "cm")
```

```{r}
# Save prediction df
write_csv(preds, paste0(home, "/output/gam_predicted_temps.csv"))
```

If we want to get uncertainty, we can use nsim instead; this simulates from the linear predictor using the inverse precision matrix, which is a fast way to get a distribution of samples from which we can take e.g. quantiles and means. However, it's still slow, so the code below isn't executed yet.

```{r}
#| eval: false
nd_sim <- data.frame(expand.grid(yday = seq(min(d$yday), max(d$yday), by = 1),
                                 area = unique(d$area),
                                 year = unique(d$year))) |>
  mutate(source = "logger") |>
  mutate(id = paste(year, area, sep = "_"),
         source_f = as.factor(source),
         year_f = as.factor(year))

# Trim!
nd_sim <- left_join(nd_sim, gdat, by = "area")

nd_sim <- nd_sim |>
  mutate(growth_dat = ifelse(year > min, "Y", "N")) |>
  filter(growth_dat == "Y") |>
  filter(yday %in% c(gs_min:gs_min)) |>
  mutate(area = as.factor(area))

# Predict!
nsim <- 500
m_pred_sims <- predict(m, newdata = nd_sim, nsim = nsim)

# Join sims with prediction data
nd_sim_long <- cbind(nd_sim, as.data.frame(m_pred_sims)) |>
    pivot_longer(c((ncol(nd_sim) + 1):(nsim + ncol(nd_sim))))

# Summarize sims over growing season
sum_pred_gs <- nd_sim_long |>
    ungroup() |>
    group_by(year, area) |>
    summarise(lwr = quantile(value, prob = 0.1),
              est = quantile(value, prob = 0.5),
              upr = quantile(value, prob = 0.9)) |>
    ungroup()

# In order to have a lower temperature in before-nuclear times (without any data to inform that), we can use the nearby areas..
sum_pred_gs <- preds |>
  mutate(keep = "Y",
         keep = ifelse(area == "BT" & year < 1980, "N", keep),
         keep = ifelse(area == "SI_HA" & year < 1972, "N", keep)) |>
  filter(keep == "Y")

sum_pred_gs_sub <- preds |>
  mutate(keep = "N",
         keep = ifelse(area == "FM" & year < 1980, "Y", keep), # use FM instead of BT
         keep = ifelse(area == "SI_EK" & year < 1972, "Y", keep)) |> # use SI_EK instead of SI_HA
  filter(keep == "Y")

# Now change the labels to BT and SI_EK...
sum_pred_gs_sub <- sum_pred_gs_sub |>
  mutate(area = ifelse(area == "FM", "BT", "SI_HA"))

# Bind rows and plot only the temperature series we will use for growth modelling
sum_pred_gs <- bind_rows(sum_pred_gs, sum_pred_gs_sub) |> select(-keep, -type)

order <- sum_pred_gs |>
  group_by(area) |>
  summarise(mean_temp = mean(temp)) |>
  arrange(desc(mean_temp))
```